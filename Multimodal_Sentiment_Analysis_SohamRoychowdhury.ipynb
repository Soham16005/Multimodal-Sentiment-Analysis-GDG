{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fx3LPid9oo5B"},"outputs":[],"source":["!pip install -U transformers\n","!pip install -U accelerate\n","!pip install -U datasets\n","!pip install -U bertviz\n","!pip install -U umap-learn\n","!pip install seaborn --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAxX4AZN91k2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVy59X5jtHa-"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IMDB Dataset.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCFDRIeWupbx"},"outputs":[],"source":["df.info()\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-xldYPqu4cT"},"outputs":[],"source":["df['sentiment'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"4Z41GuVnv5e_"},"source":["# Dataset Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"suTIhPEqvMyi"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XudiPuWZwMlH"},"outputs":[],"source":["label_counts = df['sentiment'].value_counts(ascending=True)\n","label_counts.plot.barh()\n","plt.title(\"Frequency of Classes\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GrHyoIz8wkPT"},"outputs":[],"source":["df['Words per Tweet'] = df['review'].str.split().apply(len)\n","df.boxplot(\"Words per Tweet\", by=\"sentiment\")"]},{"cell_type":"markdown","metadata":{"id":"uOgNKih5yNVe"},"source":["#Text to Token Conversion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PuhcCz5Jx31X"},"outputs":[],"source":["from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7kfj9uByUgv"},"outputs":[],"source":["model_ckpt = \"bert-base-uncased\"  #ENGLISH english\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","\n","\n","text = \"We love to sleep! Winters are awesome!\"\n","encoded_text = tokenizer(text)\n","print(encoded_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85b-m_oMyetI"},"outputs":[],"source":["len(tokenizer.vocab),tokenizer.vocab_size, tokenizer.model_max_length"]},{"cell_type":"markdown","metadata":{"id":"_l2St9Yfz5Ou"},"source":["# Data Loader and Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXABQdTvz8vn"},"outputs":[],"source":["\n","from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(df, test_size=0.3, stratify=df['sentiment'])\n","test, validation = train_test_split(test, test_size=1/3, stratify=test['sentiment'])\n","train.shape, test.shape, validation.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdtZWxSozhvw"},"outputs":[],"source":["from datasets import Dataset, DatasetDict\n","\n","dataset = DatasetDict({\n","    \"train\": Dataset.from_pandas(train, preserve_index=False),\n","    \"test\": Dataset.from_pandas(test, preserve_index=False),\n","    \"validation\": Dataset.from_pandas(validation, preserve_index=False)\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7-txgzZAdtq"},"outputs":[],"source":["dataset"]},{"cell_type":"markdown","metadata":{"id":"a6I7RSA82-Hv"},"source":["#Tokenization of emotion/sentiment data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAU99OvUAh5l"},"outputs":[],"source":["dataset['train'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuDB2S1EAomt"},"outputs":[],"source":["def tokenize(batch):\n","    temp= tokenizer(batch['review'], padding=True, truncation=True, return_token_type_ids=True,)\n","    return temp\n","\n","print(tokenize(dataset['train'][:2]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMMoLAwL2G2A"},"outputs":[],"source":["emotion_encoded=dataset.map(tokenize, batched=True, batch_size=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GrjkF8aV899b"},"outputs":[],"source":["label2id = {x['sentiment']:x['sentiment'] for x in dataset ['train']}\n","id2label = {v:k for k,v in label2id.items()}\n","label2id, id2label"]},{"cell_type":"code","source":["label2id = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}  # Update as needed\n","\n","# Apply the mapping to all splits\n","emotion_encoded = emotion_encoded.map(lambda x: {\"sentiment\": label2id[x[\"sentiment\"]]})"],"metadata":{"id":"rFVU0QxnLN1y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fK3SZEnDAPSv"},"source":["#Model Building"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cs-1tsD293z8"},"outputs":[],"source":["from transformers import AutoModel\n","import torch"]},{"cell_type":"code","source":[],"metadata":{"id":"Sk4u3c8HA0pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78qAUUxwAZYg"},"outputs":[],"source":["model= AutoModel.from_pretrained(model_ckpt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4m6401MsAfOK"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJVCAr6AAsyr"},"outputs":[],"source":["model.config\n","model_two=\"bert-base-cased\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bqNnPp9BioT"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, AutoConfig\n","Num_labels = len(label2id)\n","device = torch.device (\"cuda\" if torch. cuda.is_available() else \"cpu\")\n","config = AutoConfig.from_pretrained(model_ckpt, label2id=label2id, id2label=id2label)\n","model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, config=config).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hVGyNVL9Dfox"},"outputs":[],"source":["device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0szR-WaTFHi5"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiwS8PY8FePn"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","batch_size=8\n","training_dir = \"bert_base_training_dir\"\n","training_args= TrainingArguments(output_dir = training_dir,\n","              overwrite_output_dir = True,\n","              num_train_epochs = 2,\n","              learning_rate = 2e-5,\n","              per_device_train_batch_size = batch_size,\n","              per_device_eval_batch_size = batch_size,\n","              weight_decay = 0.01,\n","              evaluation_strategy = 'epoch',\n","              disable_tqdm = False\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2u5JoYZYGgG_"},"outputs":[],"source":["! pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2KgeAP2HVJP"},"outputs":[],"source":["print(emotion_encoded[\"train\"].features)"]},{"cell_type":"code","source":["emotion_encoded = emotion_encoded.rename_column(\"sentiment\", \"labels\")\n"],"metadata":{"id":"-rl8QuSOHsZj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Jo-z_vpIeH8"},"source":["other than the above method, you can also use sklearn to calc accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkSFHeKSITjE"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_metrics (pred) :\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","    acc = accuracy_score(labels, preds)\n","    return {\"accuracy\": acc, \"f1\": f1}"]},{"cell_type":"markdown","metadata":{"id":"a3AM3brXJRpI"},"source":["#Build Model and Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfXMvHH4JKxR"},"outputs":[],"source":["from transformers import Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=emotion_encoded['train'],\n","    eval_dataset=emotion_encoded['validation'],\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nz_0rKbLJyCu"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKr-j421J2UD"},"outputs":[],"source":["preds_output = trainer predict(emotion_encoded[ 'test'])\n","preds_output.metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1UKshf2_Qutm"},"outputs":[],"source":["preds_output.predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8GzeRJ8Veqz"},"outputs":[],"source":["y_pred = np.argmax(preds_output.predictions, axis=1)\n","y_true = emotion_encoded['test'][:]['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2tz5GFtWAgs"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_true, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VG-4XXwkWNPv"},"outputs":[],"source":["label2id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nn9h1jbpWQQ1"},"outputs":[],"source":["cm = confusion_matrix(y_true, y_pred)\n","\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, xticklabels=label2id.keys(), yticklabels=label2id.keys(), fmt ='d', cbar=False, cmap='Reds')\n","plt.yabel(\"Actual\")\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"t0A7gfUZXDMN"},"source":["#Build Prediction function and save model"]},{"cell_type":"code","source":["model_path = '/content/drive/MyDrive/Colab Notebooks/bert-base-uncased-sentiment-model'\n"],"metadata":{"id":"RbDufMcW9jQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, BertTokenizer\n","\n","# Load the model\n","model = BertForSequenceClassification.from_pretrained(model_path)\n","\n","# Load the tokenizer (optional, if needed for inference)\n","tokenizer = BertTokenizer.from_pretrained(model_path)\n"],"metadata":{"id":"NVLVJ3pw9pOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# Sample text\n","text = \"the movie was good!\"\n","\n","# Tokenize the input text\n","inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n","\n","# Perform inference\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Get the predicted class\n","predicted_class = outputs.logits.argmax(dim=-1).item()\n","if(predicted_class==0):\n","  print(\"Positive\")\n","else:\n","  print(\"Negative\")\n","\n"],"metadata":{"id":"bVFXXOQG93YT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id2label={1:'Positive',0: 'Negative'}"],"metadata":{"id":"P0rzHDdWBrwu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VtTjBkxZXnlZ"},"outputs":[],"source":["text = \"I am super happy today\"\n","def get_prediction (text) :\n","    input_encoded = tokenizer(text, return_tensors='pt')\n","    with torch.no_grad():\n","      outputs = model(**input_encoded)\n","    logits = outputs. logits\n","    pred = torch.argmax(logits, dim=1) .item()\n","    return id2label[pred]\n","get_prediction (text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-T0Ub4DYlgY"},"outputs":[],"source":["trainer.save_model(\"bert-base-uncased-sentiment-model\")"]},{"cell_type":"code","source":["from transformers import pipeline, AutoTokenizer, BertForSequenceClassification\n","\n","# Define paths\n","model_path = '/content/drive/MyDrive/bert-base-uncased-sentiment-model'\n","\n","# Load the model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/Colab Notebooks/bert-base-uncased-sentiment-model')\n","model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Colab Notebooks/bert-base-uncased-sentiment-model')\n","\n","# Create the pipeline\n","classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\n","\n","# Perform predictions\n","text = \"This is a great day!\"\n","predictions = classifier([text, 'A very good day indeed', \"We loved MTH111\", \"I am feeling anxious\"])\n","\n","# Print predictions\n","for prediction in predictions:\n","    print(prediction)\n"],"metadata":{"id":"mlWQGr7zCNtW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpFIgySnY5Pi"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJkiw3yWZaVZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mX8afXtKazZ1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}